{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import  math                                                                             \n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from geopy.distance import geodesic as GD\n",
    "import os\n",
    "import random\n",
    "import networkx as nx\n",
    "import time\n",
    "save_path = './Trajectory_Reconstruction/data_experiment'\n",
    "E_data_name = 'yancheng'\n",
    "data_path = '{}/{}/RN_model_data/roadnet'.format(save_path,E_data_name)\n",
    "save_path_map = '{}/{}'.format(save_path,E_data_name)\n",
    "save_path_rn = '{}/{}/RN_model_data'.format(save_path,E_data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Obtain a graph whose edges are nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATA2/lvxiaoling/.local/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: read_shp is deprecated and will be removed in 3.0.See https://networkx.org/documentation/latest/auto_examples/index.html#geospatial.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "rn_dir =  '{}/{}osm1'.format(save_path_map,E_data_name)\n",
    "g = nx.read_shp(rn_dir, simplify=True, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50909"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g.edges()) # yancheng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120.5138333, 32.6580336) {'osmid': 679120638, 'y': 32.6580336, 'x': 120.5138333, 'ref': '88', 'highway': 'motorway_junction', 'street_cou': 3, 'ShpName': 'nodes'}\n"
     ]
    }
   ],
   "source": [
    "for n, data in g.nodes(data=True):\n",
    "    print(n,data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_uid = []\n",
    "for u, v, data in g.edges(data=True):\n",
    "    raw_uid.append(data['u'])\n",
    "    raw_uid.append(data['v'])\n",
    "a = Counter(raw_uid)\n",
    "a = dict(sorted(a.items()))\n",
    "raw2new_uid = {key:i for i,key in enumerate(a.keys())}\n",
    "\n",
    "features = []\n",
    "lat_lng = []\n",
    "\n",
    "node2eid = {}\n",
    "for edgeNum,(u, v, data) in enumerate(g.edges(data=True)):\n",
    "    u_id = raw2new_uid[data['u']]\n",
    "    v_id = raw2new_uid[data['v']]\n",
    "    node2eid[(u_id,v_id)] = edgeNum+1\n",
    "   \n",
    "    data_lng_lat = data['Wkt'][11:][1:-1].split(',')\n",
    "    single_lat_lng = []\n",
    "    for k in data_lng_lat:\n",
    "        k = k.strip()\n",
    "        single_lat_lng.append((float(k.split(' ')[1]),float(k.split(' ')[0])))\n",
    "    lat_lng.append(single_lat_lng)\n",
    "    features.append(data['highway'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea = []\n",
    "a = Counter(features)\n",
    "a = dict(sorted(a.items()))\n",
    "code_dict = {key:i for i,key in enumerate(a.keys())}\n",
    "for value in features:\n",
    "    fea.append([code_dict[value]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(nodes,  node_attrs={}, is_directed=True):\n",
    "    g = nx.DiGraph()\n",
    "    # add nodes\n",
    "    for node in nodes:\n",
    "        g.add_node(node, **node_attrs.get(node, node_attrs))\n",
    "    return g\n",
    "# example usage\n",
    "nodes = [ i for i in range(len(g.edges()))]\n",
    "node_attrs = {s_node:{'eid': i+1,'zone_area':((np.min([sv[1] for sv in lat_lng[i]]),np.min([ sv[0] for sv in lat_lng[i]]),np.max([ sv[1] for sv in lat_lng[i]]),np.max([ sv[0] for sv in lat_lng[i]]))),'coords':lat_lng[i],\"features\":fea[i]} for i,s_node in enumerate(nodes)}\n",
    "edge_g = create_graph(nodes,node_attrs=node_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(edge_g, '{}/{}_graph.gpickle'.format(save_path_map,E_data_name))\n",
    "edge_g = nx.read_gpickle('{}/{}_graph.gpickle'.format(save_path_map,E_data_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50909"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edge_g.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yancheng:zone_range = [32.5928664, 119.455292, 34.4636842, 120.9120622]\n"
     ]
    }
   ],
   "source": [
    "lat = [ single_value[0] for value in lat_lng for single_value in value]\n",
    "lng = [ single_value[1] for value in lat_lng for single_value in value]\n",
    "print('{}:zone_range = [{}, {}, {}, {}]'.format(E_data_name,min(lat),min(lng),max(lat),max(lng)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2  get roadnet edgeOSM.txt and wayTypeOSM.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jnli/.conda/envs/RNTrajRec/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: read_shp is deprecated and will be removed in 3.0.See https://networkx.org/documentation/latest/auto_examples/index.html#geospatial.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "rn_dir =  '{}/{}osm1'.format(save_path_map,E_data_name)\n",
    "g = nx.read_shp(rn_dir, simplify=True, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1  get edge osm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = '{}/roadnet/edgeOSM.txt'.format(save_path_rn)\n",
    "\n",
    "raw_uid = []\n",
    "lat_lng = []\n",
    "features = []\n",
    "for u, v, data in g.edges(data=True):\n",
    "    raw_uid.append(data['u'])\n",
    "    raw_uid.append(data['v'])\n",
    "a = Counter(raw_uid)\n",
    "a = dict(sorted(a.items()))  # 按键排列\n",
    "raw2new_uid = {key: i for i, key in enumerate(a.keys())}\n",
    "\n",
    "with open(output_file, 'w') as file:\n",
    "    for edgeNum, (u, v, data) in enumerate(g.edges(data=True)):\n",
    "        u_id = raw2new_uid[data['u']]\n",
    "        v_id = raw2new_uid[data['v']]\n",
    "\n",
    "        data_lng_lat = data['Wkt'][11:][1:-1].split(',')\n",
    "        num = len(data_lng_lat)\n",
    "        single_lat_lng = []\n",
    "        for k in data_lng_lat:\n",
    "            k = k.strip()\n",
    "            single_lat_lng.append(float(k.split(' ')[1]))\n",
    "            single_lat_lng.append(float(k.split(' ')[0]))\n",
    "\n",
    "        file.write(f\"{edgeNum} {u_id} {v_id} {num} {' '.join(map(str, single_lat_lng))}\\n\")\n",
    "\n",
    "        lat_lng.append(single_lat_lng)   \n",
    "        features.append(data['highway'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2  get way type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_code = []\n",
    "a = Counter(features)\n",
    "a = dict(sorted(a.items()))\n",
    "code_dict = {key:i for i,key in enumerate(a.keys())}\n",
    "features_code = [code_dict[value] for value in features]\n",
    "len(Counter(features_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = '{}/roadnet/wayTypeOSM.txt'.format(save_path_rn)\n",
    "with open(output_file, 'w') as file:\n",
    "    for index, value in enumerate(features):\n",
    "        file.write(f\"{index} {value} {features_code[index]}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 save the trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 process the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traj = pd.read_parquet('{}/trajectories/00000-517-b88240ee-2707-4e1f-ba89-58fe763ea37c-00001.parquet'.format(save_path_map))\n",
    "uid_counter = Counter(df_traj['user_id'])\n",
    "sorted_uids = sorted(uid_counter.keys())\n",
    "uid_mapping = {uid: i for i, uid in enumerate(sorted_uids)} \n",
    "df_traj['user_id'] = df_traj['user_id'].apply(lambda x: uid_mapping[x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8188/8188 [03:45<00:00, 36.35it/s]\n"
     ]
    }
   ],
   "source": [
    "a = Counter(df_traj['trip_id'])\n",
    "#len(a.keys())# 10000\n",
    "groups = df_traj.groupby(df_traj.trip_id)# len(groups) 10000\n",
    "traj_dict = defaultdict()\n",
    "for key in tqdm(a.keys()):\n",
    "    traj_dict[key] = groups.get_group(key)\n",
    "    traj_dict[key] = traj_dict[key].sort_values(by=['timestamp'],ascending=[True]).reset_index(drop=True)\n",
    "    uid_value = traj_dict[key]['user_id'][0]\n",
    "    traj_dict[key] = traj_dict[key].drop(columns=['user_id'])\n",
    "    \n",
    "    traj_dict[key]['timestamp_long'] = traj_dict[key]['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    traj_dict[key]['timestamp_long'] = pd.to_datetime(traj_dict[key]['timestamp_long'])\n",
    "    time_pre = pd.DataFrame()\n",
    "    time_pre['timestamp_long'] = pd.date_range(start=traj_dict[key]['timestamp_long'][0], end=traj_dict[key]['timestamp_long'][len(traj_dict[key])-1], freq='1S')\n",
    "    new_df = pd.merge(time_pre,traj_dict[key], on='timestamp_long',how='outer')#\n",
    "    new_df  = new_df.groupby(['timestamp_long']).mean().reset_index()\n",
    "    new_df[[\"latitude\",\"longitude\",\"speed\"]] = new_df[[\"latitude\",\"longitude\",\"speed\"]].interpolate()\n",
    "    traj_dict[key] = new_df\n",
    "    traj_dict[key]['timestamp'] = traj_dict[key]['timestamp_long'].apply(lambda x: int(x.timestamp()))\n",
    "    traj_dict[key]['timestamp'] = traj_dict[key]['timestamp'].astype(int)\n",
    "    \n",
    "    uid = {'uid': [uid_value] * len(traj_dict[key])}  \n",
    "    traj_dict[key]['uid'] = pd.DataFrame(uid)\n",
    "    traj_dict[key]['speed'] = traj_dict[key]['speed']/1000 # km/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_dict = {int(key): value for key, value in traj_dict.items() if len(traj_dict[key]) != 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8183"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traj_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save well\n"
     ]
    }
   ],
   "source": [
    "np.save('{}/traj_dict.npy'.format(save_path_map),traj_dict)\n",
    "print('save well')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8183"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traj_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 decide a area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_longitude = float('inf')\n",
    "max_longitude = float('-inf')\n",
    "min_latitude = float('inf')\n",
    "max_latitude = float('-inf')\n",
    "\n",
    "\n",
    "for df in traj_dict.values():\n",
    "    min_longitude = min(min_longitude, df['longitude'].min())\n",
    "    max_longitude = max(max_longitude, df['longitude'].max())\n",
    "    min_latitude = min(min_latitude, df['latitude'].min())\n",
    "    max_latitude = max(max_latitude, df['latitude'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3  generate traj_dict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8183\n",
      "[1501499985030737920, 1504333203681460224, 3951405212996569, 1508971710441996288, 1510528269332660224, 3956605073928317, 1518784835257253888, 1519483109639340032, 3963699746525458, 1531114749079732224, 1542142463291092992, 3964042283025088, 3965059453236096, 3966840040894762, 3944329632330256, 1500743840020230144, 3951917441896828, 3952338276529107, 3953841766114067, 1506916200179974144]\n"
     ]
    }
   ],
   "source": [
    "traj_dict= np.load('{}/traj_dict.npy'.format(save_path_map),allow_pickle=True).item()\n",
    "print(len(traj_dict))\n",
    "print(list(traj_dict.keys())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list= list(traj_dict.keys())[:10]\n",
    "traj_dict_test = {key:traj_dict[key] for key in keys_list}\n",
    "len(traj_dict_test)\n",
    "np.save('{}/traj_dict_test.npy'.format(save_path_map),traj_dict_test) # 注意带上后缀名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_long</th>\n",
       "      <th>speed</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-09 10:07:46</td>\n",
       "      <td>0.00451</td>\n",
       "      <td>120.141972</td>\n",
       "      <td>33.371805</td>\n",
       "      <td>1646820466</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-09 10:07:47</td>\n",
       "      <td>0.00463</td>\n",
       "      <td>120.141913</td>\n",
       "      <td>33.371795</td>\n",
       "      <td>1646820467</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-09 10:07:48</td>\n",
       "      <td>0.00536</td>\n",
       "      <td>120.141864</td>\n",
       "      <td>33.371785</td>\n",
       "      <td>1646820468</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-09 10:07:49</td>\n",
       "      <td>0.00561</td>\n",
       "      <td>120.141818</td>\n",
       "      <td>33.371763</td>\n",
       "      <td>1646820469</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-09 10:07:50</td>\n",
       "      <td>0.00555</td>\n",
       "      <td>120.141771</td>\n",
       "      <td>33.371744</td>\n",
       "      <td>1646820470</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>2022-03-09 10:37:44</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>120.136199</td>\n",
       "      <td>33.345900</td>\n",
       "      <td>1646822264</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>2022-03-09 10:37:45</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>120.136216</td>\n",
       "      <td>33.345829</td>\n",
       "      <td>1646822265</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>2022-03-09 10:37:46</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>120.136233</td>\n",
       "      <td>33.345759</td>\n",
       "      <td>1646822266</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>2022-03-09 10:37:47</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>120.136250</td>\n",
       "      <td>33.345688</td>\n",
       "      <td>1646822267</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>2022-03-09 10:37:48</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>120.136267</td>\n",
       "      <td>33.345617</td>\n",
       "      <td>1646822268</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1803 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp_long    speed   longitude   latitude   timestamp  uid\n",
       "0    2022-03-09 10:07:46  0.00451  120.141972  33.371805  1646820466  346\n",
       "1    2022-03-09 10:07:47  0.00463  120.141913  33.371795  1646820467  346\n",
       "2    2022-03-09 10:07:48  0.00536  120.141864  33.371785  1646820468  346\n",
       "3    2022-03-09 10:07:49  0.00561  120.141818  33.371763  1646820469  346\n",
       "4    2022-03-09 10:07:50  0.00555  120.141771  33.371744  1646820470  346\n",
       "...                  ...      ...         ...        ...         ...  ...\n",
       "1798 2022-03-09 10:37:44  0.00000  120.136199  33.345900  1646822264  346\n",
       "1799 2022-03-09 10:37:45  0.00000  120.136216  33.345829  1646822265  346\n",
       "1800 2022-03-09 10:37:46  0.00000  120.136233  33.345759  1646822266  346\n",
       "1801 2022-03-09 10:37:47  0.00000  120.136250  33.345688  1646822267  346\n",
       "1802 2022-03-09 10:37:48  0.00000  120.136267  33.345617  1646822268  346\n",
       "\n",
       "[1803 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_dict[1501499985030737920]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4  split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_traj(traj_dict,traj_dict_name):\n",
    "\n",
    "    total_keys = len(traj_dict)\n",
    "    sub_dict_size = total_keys // \n",
    "\n",
    "    sub_dicts = []\n",
    "    for i in range(0, total_keys, sub_dict_size):\n",
    "        sub_dict = {k: traj_dict[k] for k in list(traj_dict.keys())[i:i + sub_dict_size]}\n",
    "        sub_dicts.append(sub_dict)\n",
    "    \n",
    "    for i in tqdm(range(len(sub_dicts))):\n",
    "        traj_dict_split = sub_dicts[i]\n",
    "        np.save('{}/{}_{}.npy'.format(save_path_map,traj_dict_name,i),traj_dict_split)\n",
    "\n",
    "    print('split well')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 15.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split well\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "traj_dict = np.load('{}/traj_dict.npy'.format(save_path_map),allow_pickle=True).item()\n",
    "split_traj(traj_dict,'traj_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNTrajRec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d2c4f983b69bd5ef2f216bc993888e4c49d8ea78f9c641eb5979f9330a82418"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
