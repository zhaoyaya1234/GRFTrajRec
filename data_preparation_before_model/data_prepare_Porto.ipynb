{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import  math      \n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.distance import geodesic as GD\n",
    "import folium\n",
    "import os\n",
    "import random\n",
    "import networkx as nx\n",
    "import time\n",
    "from pre_processing.road_network_route import load_rn_shp_route\n",
    "import ast\n",
    "save_path = './Trajectory_Reconstruction/data_experiment'\n",
    "E_data_name = 'Porto'\n",
    "data_path_raw = '{}/{}/RN_model_data/roadnet_raw'.format(save_path,E_data_name)\n",
    "data_path = '{}/{}/RN_model_data/roadnet'.format(save_path,E_data_name)\n",
    "save_path_map = '{}/{}'.format(save_path,E_data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1  Delete duplicate edges inside the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_edgeOSM(input_file, output_file):\n",
    "    unique_edges = {}  \n",
    "    line_mapping = {}  \n",
    "    new2raw_mapping = {}\n",
    "\n",
    "    with open(input_file, 'r') as file:\n",
    "        for idx,line in enumerate(file):\n",
    "            data = line.strip().split('\\t')\n",
    "\n",
    "            edge_id = int(data[0])\n",
    "            edge_start = int(data[1])\n",
    "            edge_end = int(data[2])\n",
    "\n",
    "            coords_count = int(data[3])\n",
    "            start_latitude,start_longitude = float(data[4]), float(data[5])\n",
    "            end_longitude, end_latitude = float(data[-1]), float(data[-2])\n",
    "\n",
    "            coords_str = \"\\t\".join(data[4:])\n",
    "         \n",
    "            edge_key = ((start_latitude,start_longitude),(end_latitude,end_longitude))\n",
    "            if edge_key not in unique_edges.keys():\n",
    "                unique_edges[edge_key] = (len(unique_edges), edge_start, edge_end, coords_count, coords_str,idx)\n",
    "                line_mapping[idx] = len(unique_edges)-1\n",
    "                new2raw_mapping[len(unique_edges)-1] = idx\n",
    "            else:\n",
    "                line_mapping[idx] = line_mapping[unique_edges[edge_key][-1]]\n",
    "                if coords_count > int(unique_edges[edge_key][3]):\n",
    "                    new2raw_mapping[line_mapping[unique_edges[edge_key][-1]]] = idx\n",
    "                    unique_edges[edge_key] =  (line_mapping[unique_edges[edge_key][-1]], edge_start, edge_end, coords_count, coords_str,idx)\n",
    "                    \n",
    "    \n",
    "    unique_edges = dict(sorted(unique_edges.items(), key=lambda item: item[1][0])) # eid  from 0 to big\n",
    " \n",
    "    with open(output_file, 'w') as outfile:\n",
    "   \n",
    "        for edge_data in unique_edges.values():\n",
    "            outfile.write(\"\\t\".join(str(item) for item in edge_data[:-1]) + \"\\n\")\n",
    "\n",
    "    return line_mapping,unique_edges,new2raw_mapping\n",
    "\n",
    "\n",
    "\n",
    "input_file = '{}/edgeOSM.txt'.format(data_path_raw)\n",
    "output_file = '{}/edgeOSM.txt'.format(data_path)\n",
    "line_mapping,unique_edges,new2raw_mapping = process_edgeOSM(input_file,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39935"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(unique_edges.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40267"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39935"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new2raw_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lines_by_mapping(input_file, output_file, mapping_values):\n",
    "\n",
    "    with open(input_file, 'r') as file:\n",
    "        way_data = []\n",
    "        for idx,line in enumerate(file):\n",
    "            data = line.strip().split('\\t')\n",
    "            if idx in new2raw_mapping.values():\n",
    "                data[0] = line_mapping[idx]\n",
    "                way_data.append(data)\n",
    "    way_data = sorted(way_data, key=lambda item: item[0]) # eid  from 0 to big\n",
    "    with open(output_file, 'w') as outfile:\n",
    "     \n",
    "        for data in way_data:\n",
    "            outfile.write(\"\\t\".join(str(item) for item in data) + \"\\n\")\n",
    "    return way_data\n",
    "# 主程序\n",
    "wayTypeOSM_file = \"{}/wayTypeOSM.txt\".format(data_path_raw)\n",
    "output_file = \"{}/wayTypeOSM.txt\".format(data_path)\n",
    "way_data = filter_lines_by_mapping(wayTypeOSM_file, output_file, new2raw_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39935"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(way_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Get the graph structure with edges as nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "way type number 7\n"
     ]
    }
   ],
   "source": [
    "way_type = []\n",
    "features = []\n",
    "lat_lng = []\n",
    "edgeNum = 0\n",
    "\n",
    "wayFile = open(data_path + '/wayTypeOSM.txt')\n",
    "for line in wayFile.readlines():\n",
    "    item_list = line.strip().split()\n",
    "    roadId = int(item_list[0])\n",
    "    wayId = int(item_list[-1])\n",
    "    way_type.append(wayId)\n",
    "print('way type number',len(Counter(way_type)))\n",
    "edgeFile = open(data_path + '/edgeOSM.txt')\n",
    "for line in edgeFile.readlines():\n",
    "    item_list = line.strip().split()\n",
    "    u_id = int(item_list[1])\n",
    "    v_id = int(item_list[2])  # frome u_id to v_id\n",
    "\n",
    "    single_lat_lng = []\n",
    "    num = int(item_list[3])\n",
    "    for i in range(num):\n",
    "        tmplat = float(item_list[4 + i * 2])\n",
    "        tmplon = float(item_list[5 + i * 2])\n",
    "        single_lat_lng.append((float(tmplat),float(tmplon)))\n",
    "    lat_lng.append(single_lat_lng)\n",
    "    \n",
    "    # Calculate the distance using geodesic  wrong count method  , This method is a two-point distance, not a road network distance.\n",
    "    # lat1, lon1 = single_lat_lng[0]\n",
    "    # lat2, lon2 = single_lat_lng[-1]\n",
    "    # length = GD((lat1, lon1), (lat2, lon2)).m\n",
    "\n",
    "    features.append([way_type[edgeNum]])\n",
    "    edgeNum+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39935"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is constructed as a directed graph\n",
    "def create_graph(nodes, node_attrs={},  is_directed=True):\n",
    "    g = nx.DiGraph()\n",
    "    # add nodes\n",
    "    for node in nodes:\n",
    "        g.add_node(node, **node_attrs.get(node, node_attrs))\n",
    "    return g\n",
    "# example usage\n",
    "nodes = [ i for i in range(edgeNum)]\n",
    "node_attrs = {s_node:{'eid': i+1,'zone_area':((np.min([sv[1] for sv in lat_lng[i]]),np.min([ sv[0] for sv in lat_lng[i]]),np.max([ sv[1] for sv in lat_lng[i]]),np.max([ sv[0] for sv in lat_lng[i]]))),'coords':lat_lng[i],\"features\":features[i]} for i,s_node in enumerate(nodes)}\n",
    "edge_g = create_graph(nodes, node_attrs=node_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(edge_g, '{}/{}_graph.gpickle'.format(save_path_map,E_data_name))\n",
    "edge_g = nx.read_gpickle('{}/{}_graph.gpickle'.format(save_path_map,E_data_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39935"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edge_g.nodes()) #  39935"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porto:zone_range = [41.0876277, -8.7056464, 41.2103117, -8.4685492]\n"
     ]
    }
   ],
   "source": [
    "lat = [ single_value[0] for value in lat_lng for single_value in value]\n",
    "lng = [ single_value[1] for value in lat_lng for single_value in value]\n",
    "print('{}:zone_range = [{}, {}, {}, {}]'.format(E_data_name,min(lat),min(lng),max(lat),max(lng)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Get the graph structure with nodes as nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the graph to the type we want\n",
    "import networkx as nx\n",
    "def read_node_data(file_path):\n",
    "    nodes = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            node_id, latitude, longitude = line.strip().split('\\t')\n",
    "            nodes[int(node_id)] = (float(longitude), float(latitude))\n",
    "    return nodes\n",
    "aa_list = []\n",
    "def read_edge_data(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data = line.strip().split('\\t')\n",
    "            edge_id = int(data[0])\n",
    "            start_node_id = int(data[1])\n",
    "            end_node_id = int(data[2])\n",
    "            start_latitude,start_longitude = float(data[4]), float(data[5])\n",
    "            end_longitude, end_latitude = float(data[-1]), float(data[-2])\n",
    "            coordinates = [(float(data[i + 4]), float(data[i + 5])) for i in range(0, len(data[4:]), 2)]\n",
    "            aa_list.append((start_node_id,end_node_id))\n",
    "            # aa_list.append(((start_longitude, start_latitude), (end_longitude, end_latitude)))\n",
    "            edges.append((edge_id, (start_longitude, start_latitude), (end_longitude, end_latitude),start_node_id, end_node_id,coordinates))\n",
    "    return edges\n",
    "def create_graph(nodes, edges):\n",
    "    g = nx.DiGraph()\n",
    "    for node_id, (longitude, latitude) in nodes.items():\n",
    "        osmid = {'osmid':node_id}\n",
    "        g.add_node((longitude, latitude), **osmid)\n",
    "\n",
    "    for edge_id, start_coords, end_coords,start_node_id,end_node_id, coordinates in edges:\n",
    "        edge_data = {\n",
    "            'u': start_node_id,\n",
    "            'v': end_node_id,\n",
    "            'eid':edge_id+1, \n",
    "            'key': edge_id,\n",
    "            'coords':node_attrs[edge_id]['coords'],\n",
    "            'zone_area':node_attrs[edge_id]['zone_area'],\n",
    "            'Wkt': 'LINESTRING (' + ','.join(f'{lon} {lat}' for lon, lat in coordinates) + ')'\n",
    "        }\n",
    "        g.add_edge(start_coords, end_coords, **edge_data)\n",
    "\n",
    "    return g\n",
    "\n",
    "# read nodeOSM.txt,edgeOSM.txt\n",
    "node_file_path = '{}/nodeOSM.txt'.format(data_path)\n",
    "edge_file_path = '{}/edgeOSM.txt'.format(data_path)\n",
    "nodes_data = read_node_data(node_file_path)\n",
    "edges_data = read_edge_data(edge_file_path)\n",
    "\n",
    "\n",
    "graph = create_graph(nodes_data, edges_data)\n",
    "nx.write_gpickle(graph, '{}/{}_route_graph.gpickle'.format(save_path_map,E_data_name))\n",
    "graph = nx.read_gpickle('{}/{}_route_graph.gpickle'.format(save_path_map,E_data_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18154"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39935"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph.edges())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Initial processing and saving of trajectory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>20000589</td>\n",
       "      <td>1372636858</td>\n",
       "      <td>[[-8.618643,41.141412],[-8.618499,41.141376],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1372637303620000596</td>\n",
       "      <td>20000596</td>\n",
       "      <td>1372637303</td>\n",
       "      <td>[[-8.639847,41.159826],[-8.640351,41.159871],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1372636951620000320</td>\n",
       "      <td>20000320</td>\n",
       "      <td>1372636951</td>\n",
       "      <td>[[-8.612964,41.140359],[-8.613378,41.14035],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1372636854620000520</td>\n",
       "      <td>20000520</td>\n",
       "      <td>1372636854</td>\n",
       "      <td>[[-8.574678,41.151951],[-8.574705,41.151942],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372637091620000337</td>\n",
       "      <td>20000337</td>\n",
       "      <td>1372637091</td>\n",
       "      <td>[[-8.645994,41.18049],[-8.645949,41.180517],[-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRIP_ID   TAXI_ID   TIMESTAMP  \\\n",
       "0  1372636858620000589  20000589  1372636858   \n",
       "1  1372637303620000596  20000596  1372637303   \n",
       "2  1372636951620000320  20000320  1372636951   \n",
       "3  1372636854620000520  20000520  1372636854   \n",
       "4  1372637091620000337  20000337  1372637091   \n",
       "\n",
       "                                            POLYLINE  \n",
       "0  [[-8.618643,41.141412],[-8.618499,41.141376],[...  \n",
       "1  [[-8.639847,41.159826],[-8.640351,41.159871],[...  \n",
       "2  [[-8.612964,41.140359],[-8.613378,41.14035],[-...  \n",
       "3  [[-8.574678,41.151951],[-8.574705,41.151942],[...  \n",
       "4  [[-8.645994,41.18049],[-8.645949,41.180517],[-...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_data = pd.read_csv('{}/Porto/RN_model_data/traj_raw/train.csv'.format(save_path))\n",
    "traj_data= traj_data[traj_data['MISSING_DATA'] != True]\n",
    "traj_data = traj_data[['TRIP_ID','TAXI_ID','TIMESTAMP','POLYLINE']]\n",
    "traj_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(traj_data['TAXI_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'timestamp','latitude','longitude','speed','uid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_polyline_and_timestamp(row):\n",
    "    polyline_list = ast.literal_eval(row['POLYLINE'])\n",
    "    longitude_list = [point[0] for point in polyline_list]\n",
    "    latitude_list = [point[1] for point in polyline_list]\n",
    "    timestamps = [row['TIMESTAMP']]\n",
    "    for i in range(1, len(polyline_list)):\n",
    "        timestamps.append(int(timestamps[-1]) + 15)\n",
    "    return pd.Series({'longitude': longitude_list, 'latitude': latitude_list, 'timestamp': timestamps})\n",
    "\n",
    "traj_data[['longitude', 'latitude', 'timestamp']] = traj_data.apply(split_polyline_and_timestamp, axis=1)\n",
    "\n",
    "traj_data.drop(columns=['POLYLINE','TIMESTAMP'], inplace=True)\n",
    "traj_data = traj_data[traj_data['longitude'].apply(lambda x: len(x)>0)]\n",
    "traj_data = traj_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    # Haversine formula to calculate distance between two lat/lon points\n",
    "    from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    R = 6371.0  # Earth's radius in km\n",
    "\n",
    "    # Element-wise calculations for dlat and dlon\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "\n",
    "    return distance\n",
    "# Calculate speed\n",
    "def calculate_speed(dataframe):\n",
    "    # Calculate time difference between consecutive timestamps in seconds\n",
    "    time_diff = (dataframe['timestamp'] - dataframe['timestamp'].shift(1))\n",
    "    # Calculate distance between consecutive latitudes/longitudes in km\n",
    "    distance = calculate_distance(dataframe['latitude'], dataframe['longitude'],\n",
    "                                  dataframe['latitude'].shift(1), dataframe['longitude'].shift(1))\n",
    "    # Calculate speed in km/s\n",
    "    speed = distance / time_diff\n",
    "    return speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_dict = defaultdict()\n",
    "b =Counter(traj_data['TAXI_ID'])\n",
    "b = dict(sorted(b.items()))\n",
    "code_dict = {key:i for i,key in enumerate(b.keys())}\n",
    "\n",
    "for i in tqdm(range(len(traj_data))):\n",
    "    df = pd.DataFrame(traj_data.iloc[i]).T\n",
    "    df_expanded = df.explode(['longitude', 'latitude', 'timestamp'], ignore_index=True)\n",
    "    df_expanded['longitude'] = df_expanded['longitude'].astype(float).apply(pd.to_numeric)\n",
    "    df_expanded['latitude'] = df_expanded['latitude'].astype(float).apply(pd.to_numeric)\n",
    "    df_expanded['timestamp'] = df_expanded['timestamp'].astype(int).apply(pd.to_numeric)\n",
    "    \n",
    "    df_expanded['TAXI_ID'] = df_expanded['TAXI_ID'].map(code_dict)\n",
    "    df_expanded['speed'] = calculate_speed(df_expanded)\n",
    "    df_expanded['speed'].fillna(0, inplace=True)\n",
    "\n",
    "    traj_dict[df_expanded['TRIP_ID'][0]] = df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Longitude and latitude acquisition, latitude and longitude coordinate conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_dict_all = {key: value for key, value in traj_dict.items() if len(traj_dict[key]) != 1}\n",
    "np.save('{}/traj_dict_all.npy'.format(save_path_map),traj_dict_all) # 注意带上后缀名\n",
    "print('save well')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 get traj_dict in zone_area  and given length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_dict_all= np.load('{}/traj_dict_all.npy'.format(save_path_map),allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1674141/1674141 [52:10<00:00, 534.81it/s]  \n"
     ]
    }
   ],
   "source": [
    "traj_in_area = [41.121988, -8.667057, 41.177464, -8.585300]\n",
    "min_latitude, min_longitude, max_latitude, max_longitude = traj_in_area\n",
    "traj_dict_in_area = {}\n",
    "for key in tqdm(traj_dict_all.keys()):\n",
    "    latitude_check = (traj_dict_all[key]['latitude'] >= min_latitude) & (traj_dict_all[key]['latitude'] <= max_latitude)\n",
    "    longitude_check = (traj_dict_all[key]['longitude'] >= min_longitude) & (traj_dict_all[key]['longitude'] <= max_longitude)\n",
    "    if latitude_check.all() and longitude_check.all():\n",
    "        try:\n",
    "            traj_dict_all[key].rename(columns={'TAXI_ID': 'uid'}, inplace=True)\n",
    "            traj_dict_all[key]['timestamp_long'] =pd.to_datetime(traj_dict_all[key]['timestamp'], unit='s')\n",
    "        except:\n",
    "            pass\n",
    "        traj_dict_in_area[key] = traj_dict_all[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908938\n",
      "119017\n",
      "40.25688770851257\n"
     ]
    }
   ],
   "source": [
    "print(len(traj_dict_in_area))\n",
    "traj_value = [traj_dict_in_area[key] for key in traj_dict_in_area.keys()]\n",
    "length = [len(value) for value in traj_value]\n",
    "count_num = len([num for num in length if num >60])\n",
    "print(count_num)\n",
    "print(np.mean(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119017"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traj_dict_in_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save well\n"
     ]
    }
   ],
   "source": [
    "np.save('{}/traj_dict.npy'.format(save_path_map),traj_dict_in_area) # 注意带上后缀名\n",
    "print('save well')\n",
    "# traj_dict_in_area= np.load('{}/traj_dict.npy'.format(save_path_map),allow_pickle=True).item()\n",
    "# print(len(traj_dict_in_area))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 generate traj_dict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119017\n"
     ]
    }
   ],
   "source": [
    "traj_dict= np.load('{}/traj_dict.npy'.format(save_path_map),allow_pickle=True).item()\n",
    "print(len(traj_dict))\n",
    "keys_list= list(traj_dict.keys())[:10]\n",
    "traj_dict_test = {key:traj_dict[key] for key in keys_list}\n",
    "len(traj_dict_test)\n",
    "np.save('{}/traj_dict_test.npy'.format(save_path_map),traj_dict_test) # 注意带上后缀名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_traj(traj_dict,traj_dict_name):\n",
    "\n",
    "    total_keys = len(traj_dict)\n",
    "    sub_dict_size = total_keys // 10  \n",
    "\n",
    "    sub_dicts = []\n",
    "    for i in range(0, total_keys, sub_dict_size):\n",
    "        sub_dict = {k: traj_dict[k] for k in list(traj_dict.keys())[i:i + sub_dict_size]}\n",
    "        sub_dicts.append(sub_dict)\n",
    "    \n",
    "    for i in tqdm(range(len(sub_dicts))):\n",
    "        traj_dict_split = sub_dicts[i]\n",
    "        np.save('{}/{}_{}.npy'.format(save_path_map,traj_dict_name,i),traj_dict_split) # 注意带上后缀名\n",
    "\n",
    "    print('split well')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:25<00:00,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split well\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "traj_dict = np.load('{}/traj_dict.npy'.format(save_path_map),allow_pickle=True).item()\n",
    "split_traj(traj_dict,'traj_dict')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNTrajRec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d2c4f983b69bd5ef2f216bc993888e4c49d8ea78f9c641eb5979f9330a82418"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
